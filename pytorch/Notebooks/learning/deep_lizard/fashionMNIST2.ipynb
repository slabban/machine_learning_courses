{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sequential models, batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data standardization is a specific type of normalization technique. It is sometimes referred to as z-score normalization. The z-score, a.k.a. standard score, is the transformed value for each data point.\n",
    "\n",
    "To normalize a dataset using standardization, we take every value\n",
    "inside the dataset and transform it to its correspondingvalue using the following formula:\n",
    "\n",
    "z = (x - mean)/std\n",
    "\n",
    "After performing this computation on every value inside our dataset, we have a new normalized dataset of values. The mean and standard deviation values are with respect to the dataset as a whole. \n",
    "\n",
    "<i>It's important to note that when we normalize a dataset, we typically group these operations by feature. This means that the mean and standard deviation values are relative to each feature set that's being normalized. If we are working with images, the features are the RGB color channels, so we normalize each color channel with respect to the mean and standard deviation values calculated across all pixels in every images for the respective color channel. In our case we only needs to\n",
    "normalize a single color channel</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization typically occurs at the extraction and transform stages of the ETL process, we can pass the mean and std\n",
    "# via the Normalize method as such:\n",
    "# torchvision.transforms.Normalize(\n",
    "#       [meanOfChannel1, meanOfChannel2, meanOfChannel3] \n",
    "#     , [stdOfChannel1, stdOfChannel2, stdOfChannel3] \n",
    "# )\n",
    "# However, we dont have the mean and std of the channel we are working with and will need to calculate it\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='/home/slabban/machine_learning_courses/datasets'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward we will start implemention the 'num_workwers' in our dataloaders to increase the speed of our trainings. \n",
    "In a nutshell 'num_workers' specifies the amount of subprocesses can be used to read the data from disk while the main process runs.\n",
    "From the deeplizard course, the biggest improvement came when 1 num workers was added, with diminishing returns as the number as increased.\n",
    "\n",
    "This could be different for other cases, but we will stick to 1 num worker for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we are dealing with a dataset with a total size that our computer can handle in one run we can simply do this:\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
    "images, labels = next(iter(loader))\n",
    "images.mean(), images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Often times we will be dealing with huge datasets, we to tackle that case by spliting the set into batches\n",
    "# and implementing the mean and std formulas\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=1000, num_workers=1)\n",
    "\n",
    "num_of_pixels = len(train_set) * 28 * 28\n",
    "total_sum = 0\n",
    "for images, labels in loader: total_sum += images.sum()\n",
    "mean = total_sum / num_of_pixels\n",
    "\n",
    "sum_of_squared_error = 0\n",
    "for images, labels in loader: \n",
    "    sum_of_squared_error += ((images - mean).pow(2)).sum()\n",
    "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now inlcude normalization in our extract and transform steps:\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='/home/slabban/machine_learning_courses/datasets'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.3774e-08), tensor(1.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new output of this mean and std is 0 and 1 respectively \n",
    "\n",
    "loader = DataLoader(\n",
    "      train_set\n",
    "    , batch_size=len(train_set)\n",
    "    , num_workers=1\n",
    ")\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch allows us to seamlessly move data to and from our GPU as we preform computations inside our programs.\n",
    "\n",
    "When we go to the GPU, we can use the cuda() method, and when we go to the CPU, we can use the cpu() method.\n",
    "\n",
    "We can also use the to() method. To go to the GPU, we write to('cuda') and to go to the CPU, we write to('cpu'). The to() method is the preferred way mainly because it is more flexible. We'll see one example using using the first two, and then we'll default to always using the to() variant.\n",
    "\n",
    "CPU \tGPU\n",
    "cpu() \tcuda()\n",
    "to('cpu') \tto('cuda')\n",
    "\n",
    "To make use of our GPU during the training process, there are two essential requirements. These requirements are as follows, the data must be moved to the GPU, and the network must be moved to the GPU.\n",
    "\n",
    "    Data on the GPU\n",
    "    Network on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pull in the very familiar RunManager implementation\n",
    "# We are going to add a simple line at the 'add_graph' at of the tensorboard's 'Summary Writer' instance that will make our Run Manager class\n",
    "# device Agnostic. we are using the getattr() built in function to get the value of the device on the run object. \n",
    "# If the run object doesn't have a device, then cpu is returned. This makes the code backward compatible. \n",
    "# It will still work if we don't specify a device for our run\n",
    "\n",
    "# I will also add some flexibility to the class to allow us to disable tensorboard for file management\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self, tensorboard=False):\n",
    "        # TODO: extract epoch && run variables into individual classes\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "\n",
    "        self.istb = tensorboard\n",
    "        self.tb = None\n",
    "\n",
    "        self.tqdm_epoch = None\n",
    "\n",
    "    def begin_run(self, run, network, loader):\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        images, labels = next(iter(self.loader))\n",
    "\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        if(self.istb):\n",
    "            self._create_tb(run, grid, images)\n",
    "\n",
    "    def _create_tb(self, run, grid, images):\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images.to(getattr(run, 'device', 'cpu')))\n",
    "\n",
    "    def end_run(self):\n",
    "        if(self.istb):\n",
    "            self._close_tb()\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def _close_tb(self):\n",
    "        self.tb.close()\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.tqdm_epoch = tqdm(self.loader, unit=\"batch\")\n",
    "        \n",
    "    \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss /len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        if(self.istb):\n",
    "            self._plot_tb(loss, accuracy)\n",
    "            \n",
    "\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for key,val in self.run_params._asdict().items(): results[key] = val\n",
    "        self.run_data.append(results)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "\n",
    "    def _plot_tb(self, loss, accuracy):\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "        \n",
    "    def track_loss(self, loss, batch):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now also pull in our run builder class\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        # \n",
    "        Run = OrderedDict('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for vals in product(*params.values()):\n",
    "            runs.append(Run(*vals))\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets also pull in our previous Network\n",
    "\n",
    "# Lets build on our Network class by implementing the 'forward' method, which accepts and returns a tensor\n",
    "# We dont actually call this method ourselves as it is called via the __call__ function in our instantiated layers\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "       t = self.conv1(t)\n",
    "       t = F.relu(t)\n",
    "       t = F.max_pool2d(t, kernel_size =2, stride=2)\n",
    "\n",
    "       t = self.conv2(t)\n",
    "       t = F.relu(t)\n",
    "       t = F.max_pool2d(t, kernel_size =2, stride=2)\n",
    "\n",
    "       t = t.reshape(-1, 12*4*4)\n",
    "       t = self.fc1(t)\n",
    "       t = F.relu(t)\n",
    "\n",
    "       t = self.fc2(t)\n",
    "       t = F.relu(t)\n",
    "\n",
    "       t = self.out(t)\n",
    "\n",
    "       return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913796</td>\n",
       "      <td>0.657950</td>\n",
       "      <td>2.734332</td>\n",
       "      <td>2.780869</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.489622</td>\n",
       "      <td>0.813950</td>\n",
       "      <td>2.257453</td>\n",
       "      <td>5.044611</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.403654</td>\n",
       "      <td>0.850850</td>\n",
       "      <td>2.353287</td>\n",
       "      <td>7.402783</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.824287</td>\n",
       "      <td>0.693233</td>\n",
       "      <td>2.294250</td>\n",
       "      <td>2.333080</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.433806</td>\n",
       "      <td>0.839600</td>\n",
       "      <td>2.254014</td>\n",
       "      <td>4.591393</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.372124</td>\n",
       "      <td>0.861300</td>\n",
       "      <td>2.821443</td>\n",
       "      <td>7.416970</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924748</td>\n",
       "      <td>0.649367</td>\n",
       "      <td>7.425347</td>\n",
       "      <td>7.559085</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.467581</td>\n",
       "      <td>0.824517</td>\n",
       "      <td>5.560944</td>\n",
       "      <td>13.128758</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.381183</td>\n",
       "      <td>0.857817</td>\n",
       "      <td>2.306813</td>\n",
       "      <td>15.441303</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887272</td>\n",
       "      <td>0.663933</td>\n",
       "      <td>2.267377</td>\n",
       "      <td>2.305693</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463174</td>\n",
       "      <td>0.825800</td>\n",
       "      <td>2.279554</td>\n",
       "      <td>4.589933</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.392316</td>\n",
       "      <td>0.854517</td>\n",
       "      <td>2.258186</td>\n",
       "      <td>6.852948</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  0.913796  0.657950        2.734332      2.780869  0.01   \n",
       "1     1      2  0.489622  0.813950        2.257453      5.044611  0.01   \n",
       "2     1      3  0.403654  0.850850        2.353287      7.402783  0.01   \n",
       "3     2      1  0.824287  0.693233        2.294250      2.333080  0.01   \n",
       "4     2      2  0.433806  0.839600        2.254014      4.591393  0.01   \n",
       "5     2      3  0.372124  0.861300        2.821443      7.416970  0.01   \n",
       "6     3      1  0.924748  0.649367        7.425347      7.559085  0.01   \n",
       "7     3      2  0.467581  0.824517        5.560944     13.128758  0.01   \n",
       "8     3      3  0.381183  0.857817        2.306813     15.441303  0.01   \n",
       "9     4      1  0.887272  0.663933        2.267377      2.305693  0.01   \n",
       "10    4      2  0.463174  0.825800        2.279554      4.589933  0.01   \n",
       "11    4      3  0.392316  0.854517        2.258186      6.852948  0.01   \n",
       "\n",
       "    batch_size  num_workers device  shuffle  epochs  \n",
       "0         1000            1   cuda     True       3  \n",
       "1         1000            1   cuda     True       3  \n",
       "2         1000            1   cuda     True       3  \n",
       "3         1000            1   cuda    False       3  \n",
       "4         1000            1   cuda    False       3  \n",
       "5         1000            1   cuda    False       3  \n",
       "6         1000            1    cpu     True       3  \n",
       "7         1000            1    cpu     True       3  \n",
       "8         1000            1    cpu     True       3  \n",
       "9         1000            1    cpu    False       3  \n",
       "10        1000            1    cpu    False       3  \n",
       "11        1000            1    cpu    False       3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is the updated implementation of the new training loop with our normalized data and GPU implementation\n",
    "# where we pass the network to the device and each of the images and labels to the device on a per-batch basis\n",
    "\n",
    "parameters = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000]\n",
    "    , num_workers = [1]\n",
    "    , device = ['cuda', 'cpu']\n",
    "    , shuffle = [True, False]\n",
    "    , epochs = [3]\n",
    ")\n",
    "\n",
    "manager = RunManager(tensorboard=False)\n",
    "\n",
    "for run in RunBuilder.get_runs(parameters):\n",
    "    device = torch.device(run.device)\n",
    "    network = Network().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size, shuffle=run.shuffle)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    total_epochs = range(run.epochs)\n",
    "\n",
    "    manager.begin_run(run, network, train_loader)\n",
    "    for epoch in total_epochs:\n",
    "        manager.begin_epoch()\n",
    "        \n",
    "        for batch in manager.tqdm_epoch:\n",
    "\n",
    "            manager.tqdm_epoch.set_description(f\"Epoch {manager.epoch_count} of {run.epochs}\")\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # calculate gradients\n",
    "            optimizer.step() # update weights\n",
    "\n",
    "            manager.track_loss(loss, batch)\n",
    "            manager.track_num_correct(preds, labels)\n",
    "        manager.end_epoch()\n",
    "    manager.end_run()\n",
    "\n",
    "# Commenting out to prevent file overcrowding\n",
    "#manager.save('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Models\n",
    "\n",
    "The Sequential class allows us to build PyTorch neural networks on-the-fly without having to build an explicit class. This make it much easier to rapidly build networks and allows us to skip over the step where we implement the forward() method. When we use the sequential way of building a PyTorch network, we construct the forward() method implicitly by defining our network's architecture sequentially.\n",
    "\n",
    "A sequential module is a container or wrapper class that extends the nn.Module base class and allows us to compose modules together. We can compose any nn.Module with in any other nn.Module. \n",
    "\n",
    "We will go over the three ways that we can modify and create these sequential models, to avoid large text, we will use a simple network comprised of 2 fully connected layers, then convert our current network to a sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets re-instantiate our normalized train set\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='/home/slabban/machine_learning/machine_learning_courses/datasets'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define the inputs and outputs of our two layers, we use the pixel count at the input layer, reduce the output by half\n",
    "# and use the labels as the final output layer\n",
    "in_features = image.numel()\n",
    "out_features = math.floor(in_features / 2)\n",
    "out_classes = len(train_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (2): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1, passing the layers directly to the constructor\n",
    "network1 = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features, out_features)\n",
    "    ,nn.Linear(out_features, out_classes)\n",
    ")\n",
    "network1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (output): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2, we create and ordered dictionary and label the layer as a key, and pass the nn layer as the value\n",
    "# This allows us to have labelled indices and some modularity, i.e, we can now pass different types of Models to the run builder!!\n",
    "\n",
    "layers = OrderedDict([\n",
    "    ('flat', nn.Flatten(start_dim=1))\n",
    "    ,('hidden', nn.Linear(in_features, out_features))\n",
    "    ,('output', nn.Linear(out_features, out_classes))\n",
    "    ])\n",
    "\n",
    "network2 = nn.Sequential(layers)\n",
    "network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (output): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 3, we use the add_module() method to add nn.Module instances to the network after it has already been initialized\n",
    "\n",
    "network3 = nn.Sequential()\n",
    "network3.add_module('flat', nn.Flatten(start_dim=1))\n",
    "network3.add_module('hidden', nn.Linear(in_features, out_features))\n",
    "network3.add_module('output', nn.Linear(out_features, out_classes))\n",
    "network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets quickly pull our infamous network down here for some ease of visibility\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "       t = self.conv1(t)\n",
    "       t = F.relu(t)\n",
    "       t = F.max_pool2d(t, kernel_size =2, stride=2)\n",
    "\n",
    "       t = self.conv2(t)\n",
    "       t = F.relu(t)\n",
    "       t = F.max_pool2d(t, kernel_size =2, stride=2)\n",
    "\n",
    "       t = t.reshape(-1, 12*4*4)\n",
    "       t = self.fc1(t)\n",
    "       t = F.relu(t)\n",
    "\n",
    "       t = self.fc2(t)\n",
    "       t = F.relu(t)\n",
    "\n",
    "       t = self.out(t)\n",
    "\n",
    "       return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using method 1, lets create our equivalent sequential model\n",
    "\n",
    "sequential = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    , nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    , nn.Flatten(start_dim=1)  \n",
    "    , nn.Linear(in_features=12*4*4, out_features=120)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(in_features=120, out_features=60)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(in_features=60, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty handy tool that we like to employ to control the randomness of our weight initialization is the 'torch.manual_seed' method, this allows us \n",
    "to set a value of the seed that our random number generator uses.\n",
    "\n",
    "It important to note that this method will have to be called before each network is intatilized (before the layers are declared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a manual seed of 50 on our sequential model\n",
    "torch.manual_seed(50)\n",
    "sequential = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    , nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    , nn.Flatten(start_dim=1)  \n",
    "    , nn.Linear(in_features=12*4*4, out_features=120)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(in_features=120, out_features=60)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(in_features=60, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87c69a23efa0ee1d5c64982a8e9486c08d519e3aa99d691b2ceccc04345ec1d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch-fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
