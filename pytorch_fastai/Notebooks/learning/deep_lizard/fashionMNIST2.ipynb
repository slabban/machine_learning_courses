{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add regularization, num_workers, CUDA concepts, sequential models, batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data standardization is a specific type of normalization technique. It is sometimes referred to as z-score normalization. The z-score, a.k.a. standard score, is the transformed value for each data point.\n",
    "\n",
    "To normalize a dataset using standardization, we take every value\n",
    "inside the dataset and transform it to its correspondingvalue using the following formula:\n",
    "\n",
    "z = (x - mean)/std\n",
    "\n",
    "After performing this computation on every value inside our dataset, we have a new normalized dataset of values. The mean and standard deviation values are with respect to the dataset as a whole. \n",
    "\n",
    "<i>It's important to note that when we normalize a dataset, we typically group these operations by feature. This means that the mean and standard deviation values are relative to each feature set that's being normalized. If we are working with images, the features are the RGB color channels, so we normalize each color channel with respect to the mean and standard deviation values calculated across all pixels in every images for the respective color channel. In our case we only needs to\n",
    "normalize a single color channel</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization typically occurs at the extraction and transform stages of the ETL process, we can pass the mean and std\n",
    "# via the Normalize method as such:\n",
    "# torchvision.transforms.Normalize(\n",
    "#       [meanOfChannel1, meanOfChannel2, meanOfChannel3] \n",
    "#     , [stdOfChannel1, stdOfChannel2, stdOfChannel3] \n",
    "# )\n",
    "# However, we dont have the mean and std of the channel we are working with and will need to calculate it\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='/home/slabban/machine_learning_courses/datasets'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward we will start implemention the 'num_workwers' in our dataloaders to increase the speed of our trainings. \n",
    "In a nutshell 'num_workers' specifies the amount of subprocesses can be used to read the data from disk while the main process runs.\n",
    "From the deeplizard course, the biggest improvement came when 1 num workers was added, with diminishing returns as the number as increased.\n",
    "\n",
    "This could be different for other cases, but we will stick to 1 num worker for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we are dealing with a dataset with a total size that our computer can handle in one run we can simply do this:\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
    "images, labels = next(iter(loader))\n",
    "images.mean(), images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Often times we will be dealing with huge datasets, we to tackle that case by spliting the set into batches\n",
    "# and implementing the mean and std formulas\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=1000, num_workers=1)\n",
    "\n",
    "num_of_pixels = len(train_set) * 28 * 28\n",
    "total_sum = 0\n",
    "for images, labels in loader: total_sum += images.sum()\n",
    "mean = total_sum / num_of_pixels\n",
    "\n",
    "sum_of_squared_error = 0\n",
    "for images, labels in loader: \n",
    "    sum_of_squared_error += ((images - mean).pow(2)).sum()\n",
    "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now inlcude normalization in our extract and transform steps:\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='/home/slabban/machine_learning_courses/datasets'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.3774e-08), tensor(1.))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new output of this mean and std is 0 and 1 respectively \n",
    "\n",
    "loader = DataLoader(\n",
    "      train_set\n",
    "    , batch_size=len(train_set)\n",
    "    , num_workers=1\n",
    ")\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch allows us to seamlessly move data to and from our GPU as we preform computations inside our programs.\n",
    "\n",
    "When we go to the GPU, we can use the cuda() method, and when we go to the CPU, we can use the cpu() method.\n",
    "\n",
    "We can also use the to() method. To go to the GPU, we write to('cuda') and to go to the CPU, we write to('cpu'). The to() method is the preferred way mainly because it is more flexible. We'll see one example using using the first two, and then we'll default to always using the to() variant.\n",
    "\n",
    "CPU \tGPU\n",
    "cpu() \tcuda()\n",
    "to('cpu') \tto('cuda')\n",
    "\n",
    "To make use of our GPU during the training process, there are two essential requirements. These requirements are as follows, the data must be moved to the GPU, and the network must be moved to the GPU.\n",
    "\n",
    "    Data on the GPU\n",
    "    Network on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pull in the very familiar RunManager implementation\n",
    "# We are going to add a simple line at the 'add_graph' at of the tensorboard's 'Summary Writer' instance that will make our Run Manager class\n",
    "# device Agnostic. we are using the getattr() built in function to get the value of the device on the run object. \n",
    "# If the run object doesn't have a device, then cpu is returned. This makes the code backward compatible. \n",
    "# It will still work if we don't specify a device for our run\n",
    "\n",
    "# I will also add some flexibility to the class to allow us to disable tensorboard for file management\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self, tensorboard=False):\n",
    "        # TODO: extract epoch && run variables into individual classes\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "\n",
    "        self.istb = tensorboard\n",
    "        self.tb = None\n",
    "\n",
    "        self.tqdm_epoch = None\n",
    "\n",
    "    def begin_run(self, run, network, loader):\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        images, labels = next(iter(self.loader))\n",
    "\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        if(self.istb):\n",
    "            self._create_tb(run, grid, images)\n",
    "\n",
    "    def _create_tb(self, run, grid, images):\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images.to(getattr(run, 'device', 'cpu')))\n",
    "\n",
    "    def end_run(self):\n",
    "        if(self.istb):\n",
    "            self._close_tb()\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def _close_tb(self):\n",
    "        self.tb.close()\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.tqdm_epoch = tqdm(self.loader, unit=\"batch\")\n",
    "        \n",
    "    \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss /len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        if(self.istb):\n",
    "            self._plot_tb(self, loss, accuracy)\n",
    "            \n",
    "\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for key,val in self.run_params._asdict().items(): results[key] = val\n",
    "        self.run_data.append(results)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "\n",
    "    def _plot_tb(self, loss, accuracy):\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "        \n",
    "    def track_loss(self, loss, batch):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87c69a23efa0ee1d5c64982a8e9486c08d519e3aa99d691b2ceccc04345ec1d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch-fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
