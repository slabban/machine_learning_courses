{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Ops can be broken down to 3 categories:\n",
    "\n",
    "1. Shaping Operations\n",
    "2. Element-Wise Operations\n",
    "3. Reduction Operations\n",
    "4. Access Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "  [1,1,1,1],\n",
    "  [2,2,2,2],\n",
    "  [3,3,3,3]\n",
    "],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape determination\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank Determination\n",
    "len(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element calculation\n",
    "torch.tensor(t.shape).prod()\n",
    "# or \n",
    "t.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shaping Operations retain the number of elements, but can change the rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without changing the rank. Using -1 lets pytorch calculate the complementary number, if possible\n",
    "t.reshape(-1, 2).shape\n",
    "t.reshape(-1,1).shape\n",
    "t.reshape(-1,12).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeezing removes all axes that have a length of 1\n",
    "t.reshape(-1,12).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsqueezing inversely add an axis of length 1\n",
    "t.reshape(-1,12).unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening places all elements on one axis\n",
    "t.flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise operations focus on the specific elements are within the tensor, for these operations, the tensors\n",
    "should have the same shape, and implicitly, the same elements. Examples of these are arithmetic operations (add, sub, mul, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: tensor([[0.6968, 0.4054],\n",
      "        [0.1921, 0.2436]])\n",
      "t2: tensor([[0.1498, 0.5025],\n",
      "        [0.0183, 0.9419]])\n",
      "sum: tensor([[0.8467, 0.9079],\n",
      "        [0.2104, 1.1855]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(2,2)\n",
    "t2 = torch.rand(2,2)\n",
    "print('t1:',t1)\n",
    "print('t2:',t2)\n",
    "t3 = t1+t2\n",
    "print('sum:', t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important concept in element-wise operations is called <b>broadcasting</b>, I'll leave a \"todo\" here to expand on the topic is a huge barrier between the newbies and the pros, and in essense, save a ton on processing and programming, since this\n",
    "would normally be done via a for loop.\n",
    "\n",
    "This knowledge is going to be very handy during data preparation and will be seen more in normalization techniques\n",
    "\n",
    "see: https://deeplizard.com/learn/video/6_33ulFDuCg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6968, 2.4054],\n",
      "        [2.1921, 2.2436]])\n"
     ]
    }
   ],
   "source": [
    "# Here is the first example of broadcasting, the lower rank tensor, 2, is broadcasted to achieve the shape of \n",
    "# the larger tensor t1\n",
    "t_broad = t1 +2\n",
    "print(t_broad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b32ba8630eae0cf143c35cc7c8bde428688116bdb8bd122db8a27652bb35d1a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
